
‚ÑπÔ∏è [**I - Introduction**](#introduction)

‚ÑπÔ∏è [**II - Concept important**](#concept)

‚ÑπÔ∏è [**III - Etude des probl√®mes li√©es √† la propriet√© des donn√©es**](#studies)

‚ÑπÔ∏è [**IV - Quelque techniques de Nettoyage de donn√©es avec le deep learning**](#technique)


<style>
/* Line up "native" blockquotes with transcluded ones in PDF */
@media print{.internal-embed{margin-left:-30px;}}

/* Page breaks */
@media print {
  h1 { 
    page-break-before: always;
  }
  h2, h3, h4, h5, h6 {
    page-break-after: avoid;
  }
  pre, blockquote {
    page-break-inside: avoid;
  }
}
</style>


<span id="introduction"></span>
# I - Introduction 

Nous sommes au 21e si√®cle la r√©volution p√©troli√®re et √©lectronique est pass√©. Comme certains experts le disent nous sommes √† l‚Äô√®re du Big Data. Les donn√©es sont pour beaucoup l‚Äôor des 21 e si√®cle. Il est donc n√©cessaire pour tout scientifique de comprendre ceux-ci pour obtenir des r√©sultats satisfaisants. Contrairement √† ce que nous pourrions penser, les donn√©es sont omnipr√©sentes et sous diverses formes. Ceci dit, trouver d√®s la premi√®re fois des donn√©es enti√®rement exploitables n'est qu'un mythe. En tant que scientifiques, nous devions donc veiller √† l'int√©grit√© et √† la propri√©t√© des donn√©es avant de les utiliser.Avec l‚Äôexplosion du Machine learning et notamment du Big Data, cela devient encore plus v√©ridique. Ceci dit les scientifiques ont pris pour d√©fis la mise en place de techniques visant √† rendre les donn√©es propres et exploitables. Toutefois bien que le nettoyage de donn√©es est une √©tape cruciale avant la mise en place d‚Äôun algorithme de Deep Learning, **Ne serait-il pas possible d‚Äôeffectuer ce nettoyage avec du deep learning ?**


<span id="concept"></span>
# II - Concept important

## 1. Cycle de vie d‚Äôun projet de Data Science

Pour bien comprendre le processus de nettoyage des donn√©es, il faut comprendre tout d‚Äôabord comment se d√©roule un projet de **Data Science.** Un projet de Data Science se d√©roule notamment en 4 grandes √©tapes que sont:

- La collection des donn√©es
- La pr√©paration des donn√©es
- L'exploration et la visualisation des donn√©es
- L‚Äôexp√©rimentation et la pr√©diction des donn√©s

![[Data preparation | Theory (datacamp.com)](https://campus.datacamp.com/courses/data-science-for-everyone/introduction-to-data-science-1?ex=1)](inkdrop://file:6FgubTpqo)
Le nettoyage des donn√©es intervient √† la phase **de pr√©parations des donn√©es**.


## 2. Quesque le machine Learning ?

Unanimement, le ML est un sous-domaine de l'intelligence artificielle que l'on peut lui-m√™me d√©finir comme une imitation de l'intelligence humaine par une machine. Pour certains, le machine learning peut √™tre d√©fini comme un moyen d'adapter l'ordinateur aux situations pour lesquelles il n'a pas √©t√© explicitement programm√©.

## 3. Le deep Learning
<style>
  img {
    border-radius: 10px;
  }
  pre {
    background: white;
  }
</style>
![clipboard.png](inkdrop://file:tUXLzDeDz)

### Quesque le Deep learning ?
<style>
    .floater, .type-ann, #mlp {
      display:flex;
  }
  .floater p {
    flex: 3;
  }
  .type-ann  {
    flex-direction: column;
  }

</style>
<div class="floater">
  <p>Le <b>Deeplearning</b> est l'une des techniques de ML qui a r√©volutionn√© le 21e si√®cle. Son concept est fond√© sur la reproduction de la structure c√©r√©brale humaine. Ce dernier comprend des milliers de neurones connect√©s par des synapses. Nous allons donc faire quelques neurosciences pour comprendre comment ils fonctionnent et de la m√™me mani√®re comment Deeplearning fonctionne. </p>
<figure class="floater-picture">
  <img src="inkdrop://file:281c9EIna" />
<figcaption>Structure d‚Äôun Neurone Humain</figcaption>

</figure>
</div>

<div style="page-break-after: always; visibility: hidden"> 
\pagebreak 
</div>

### Comment fonctionne un neurone Biologique ?

Il faut tout d'abord remarquer que le neurone biologique est constitu√© de trois grandes parties que sont: les `dendrites`, `l'axone` et enfin `la synapse`. Le neurone re√ßoit un signal d‚Äôactivation par sa **dentrites.**  Ensuite ce signal passe par **l'axone** du neurone puis active d'autres neurone par
le biais de sa **synapse**. Ceci est souvent connu sous le nom de la **transmission synaptique**. Alors comment ce mode de communication a influenc√© le d√©veloppement du Deep Learning?

### Fonctionnement d‚Äôun r√©seau de Neurone Artificiel

La technique √† la base du succ√®s du Deep learning est le `R√©seau de Neurones Artificielle` . Celle-ci repose sur la structure des r√©seaux neuronaux, d'o√π leur nom. Il faut toutefois savoir que cette technique n‚Äôest pas li√©e au Deep Learning,  la sp√©cifi√©e du Deeplearning vient du fait qu'il peut avoir plusieurs couches de neurones interm√©diaires entre l'entr√©e et la sortie d'o√π l'appellation de cette technique.

La structure fondamentale d'un r√©seau neuronal est un neurone (`Naturally ‚úÖ`). √Ä la diff√©rence d'un neurone biologique, il aura les √©l√©ments suivants:
![clipboard.png](inkdrop://file:JY1GbE_L9)


- **Des poids:** Un r√©seau de neurones est g√©n√©ralement repr√©sent√© comme un **graphe pond√©r√©** o√π les noeuds sont les neurones. Pour chaque donn√©e entrant dans le neurone, une **branche(poids)** d'une valeur donn√©e est associ√©e √† celle-ci. Le r√©seau de neurones consistera √† trouver les meilleures pond√©rations pour chaque liaison afin de minimiser les diff√©rences entre les pr√©dictions du r√©seau et les r√©sultats concrets.
- **Un biais:**En plus de la pond√©ration, chaque neurone se voit attribuer un **biais** qui cette fois est ind√©pendant des intrants (Les donn√©es). Le r√©seau neuronne va √©galement chercher √† trouver les meilleurs poids pour chacun neuronne.
- **Une fonction d‚Äôaggr√©gation:**  Cette fonction prend toutes les entr√©es $x_i$ d'un neurone et les multiplie par le poids $w_i$ correspondant √† ces entr√©es, puis ajoute le biais neuronal.

  $$
  f = \sum(\pm1)w_i*x_i + b
  $$

- **Une fonction d‚Äôactivation:** Comme son nom l'indique, la fonction d'activation est une formule math√©matique activ√©e sous certaines conditions. Lorsque les neurones **agr√®gent** les valeurs, elles sont transmises √† la fonction d'activation, qui v√©rifie si la valeur calcul√©e est sup√©rieure au seuil requis. Il existe plusieurs fonctionnalit√©s d'activation, parmi les plus populaires sont:
    - **Sigmo√Øde**: produit une courbe en forme de S. Bien qu'elle ne soit pas lin√©aire, elle ne tient pas compte de l√©g√®res variations dans les intrants, ce qui donne des r√©sultats semblables.
    

      $$
      a(z) = \frac{1}{1+exp(-z)}
      $$

   
    - **Fonctions de tangente hyperbolique (tanh):** Il s‚Äôagit d‚Äôune fonction sup√©rieure compar√©e √† la fonction Sigmoid. Toutefois, elle tient moins compte des relations et sa convergence est plus lente.
    
      $$
      a(z) = \frac{exp(z) - exp(-z)}{exp(z) + exp(-z)}
      $$
    
    - **Unit√© lin√©aire rectifi√©e (ReLu):** Cette fonction converge plus rapidement, optimise et produit la valeur souhait√©e plus rapidement. C‚Äôest de loin la fonction d‚Äôactivation la plus populaire utilis√©e dans les couches cach√©es. D‚Äôune mani√®re simple elle renvoie 0 pour les nombres n√©gatifs et la valeur du nombre pour les nombres positifs
    
      $$
      a(z) = max(x, 0)
      $$
    
    - **Softmax:** utilis√© dans la couche de sortie car il r√©duit les dimensions et peut repr√©senter une distribution cat√©gorique. Cette fonction re√ßoit un vecteur $z = (z_1, ...., z_K)$ et pour chaque composant calcule sa valeur comme suit:

      $$
      a(z)_j = \frac{exp(z)_j}{\sum_{k=1}^{K} exp(z)_k}
      $$
    

### Type de r√©seaux de Neurone

En fonction du type d‚Äôusage, il existe une multitude r√©seaux de Neurones. Toutefois nous allons nous attarder sur quatre grands types de r√©seaux de Neurones que sont:

- **Perceptron Multicouche (MLP)**
<div class="type-ann"><p>Un perceptron est le r√©seau neuronal le plus simple √† construire. C'est un neurone unique qui agit comme une r√©gression logistique. En effet pour une entr√©e donn√©e il fournit une sortie binaire. Un perceptron Multicouche sera comme son nom l‚Äôindique form√© de multiples perceptrons sur plusieurs couches. Ils peuvent effectuer bon nombre de t√¢che comme classifier des images, des donn√©es tabulaires ou m√™me textuelles. Toutefois leur manque de sp√©cialisation est un inconv√©nient ce qui nous am√®ne aux r√©seaux de Neurones suivants.</p>
  <div id="mlp">
  <figure class="floater-picture">
  <img src="inkdrop://file:xGU4KdLoe" />
<figcaption>Structure d‚Äôun Neurone Humain</figcaption>
</figure>
<figure class="floater-picture">
  <img src="inkdrop://file:KGAHXrWj0" />
<figcaption>Perceptron Multicouche</figcaption>
    </figure></div>
</div>
- **R√©seaux de Neurone R√©current (RNN)**
<div class="type-ann"><p>Dans un perceptron multicouche le r√©sultat d‚Äôune couche de neurone est transmis √† la couche suivante car chaque couche poss√®de des param√®tre diff√©rent. Toutefois dans un R√©seaux de Neuronne r√©current, Un neurone peut conserver en m√©moire un r√©sultat pass√© pour en produire un autre r√©sultat (d‚Äôou la boucle sur le sh√©ma). On peut utiliser ce type de r√©seaux pour des s√©ries temporelle, des donn√©es textuelle ou m√™me des donn√©es audio.</p>
</figure>
<figure class="floater-picture">
  <img src="inkdrop://file:Z0htIe_gn" />
<figcaption>Diff√©rence ANN et RNN</figcaption>
    </figure>
</div>

- **R√©seaux de Neurone Convolutionnel (CNN)**
Lorsqu‚Äôon veut entrainer un r√©seau de Neurones traditionnel √† base d‚Äôimage, il existe une multitude d‚Äôop√©ration de pr√©-processing √† effectuer avant de pouvoir entrainer les r√©seaux. L‚Äôav√®nement des CNN a contribu√© drastiquement √† la r√©duction de ces op√©rations. En effet ce type de r√©seaux poss√®de des couches sp√©cialis√©es pour effectuer les op√©rations de pr√©-processing. Sans entrer dans les d√©tails, voici les couches principales :

- **couches de convolution (CONV)**
- **couches de correction (ReLU)**
- **couches de pooling (POOL)**

![clipboard.png](inkdrop://file:yQXhHMocO)

![clipboard.png](inkdrop://file:u967WSaDD)

### Algorithme de descente du gradient avec Momentum

Lorsqu‚Äôun r√©seau de donn√©es est entrain√© sur un dataset **X**  pour l‚Äô√©valuer on peut lui d√©finir une fonction qui va repr√©senter l‚Äô√©cart entre les pr√©dictions du r√©seau et les valeurs r√©elles du dataset. L‚Äôapprentissage du neurone va consister √† minimiser cette fonction co√ªt. Pour ce faire on utilise g√©n√©ralement la m√©thode de [l‚Äôalgorithme du gradient](https://fr.wikipedia.org/wiki/Algorithme_du_Gradient). Toutefois celle ci peut tomber sur un minimum local de la fonctions ce qui auras pour effet d‚Äôavoir un mod√®le sous entrain√©. Pour pallier √† ce probl√®me les scientifiques on d√©velopp√© un algorithme de gradient evolu√© avec Momentum. Un **momentum** peut √™tre d√©crit en physique comme un vecteur quantit√© de mouvement $\vec{p} = m * \vec{v}$ ou $m$ est la masse du solide et $\vec{v}$ son vecteur vitesse. Le principe seras d'utiliser pour l'it√©ration $i$ les informations utilis√© √† l'it√©ration $i-1$. En effet dans un algorithme de gradient classique, √† chaque it√©ration on a:

$$
x_{k+1} = x_k - \alpha * \nabla{f}(x_k)
$$
Dans le gradient avec **momentum** on aura:

Soit $C_k$ tel que
$C_{k + 1} = \alpha * \nabla{f}(x_{k}) + \beta * C_{k} $ avec $\alpha$ le **learning rate** et $\beta$ le** coefficient momentum** tel que $0 \leq \beta \leq 1$.

$$
x_{k+1} = x_k - C_{k + 1}
$$

Ainsi on remarque que √† chaque it√©rations $i$ la m√©thode conserve les informations de changement $C_k$ des it√©rations pr√©c√©dentes.

## 4. Apprentissage par renforcement

L'une des techniques de transformation des donn√©es par deep learning que nous verrons plus tard est effectu√©e par un algorithme de renforcement. Nous allons essayer de comprendre comment fonctionne ce genre d‚Äôalgorithmes.

## Quesque l‚Äôapprentissage par renforcement ?

![clipboard.png](inkdrop://file:VGXdHAgWI)

Contrairement au **algorithmes supervis√© ou non supervis√©** un algorithme par renforcement est un algorithme interactif dans lequels un algorithmes √©ssaie plusiseurs tentatives et est recompens√© lorqu‚Äôil effectue une tentative. Le but pour cet algorithme seras donc de maximiser sa r√©compenses. Ce type d‚Äôalgorithme est √† la base du c√©l√®bre programme **AlphaGo** qui as battu le champion du monde en Go. 

<div style="page-break-after: always; visibility: hidden"> 
\pagebreak 
</div>

## Comment fonctionne t‚Äôil?

Dans ce type d‚Äôalgorithme on distingue deux termes principaux: **L‚Äôagent** et **l‚Äôenvironnement. L‚Äôargent** est l‚Äôalgorithme qui vas se charger de l‚Äôapprentissage tandis que **l‚Äôenvironnement** est le monde dans lequel vas vivre et interagir l‚Äôagent. L‚Äôagent peut interagir avec l‚Äôenvironnement par le biais de certaines action toutefois il ne peut pas le modifier. Dans une analogie avec le monde r√©ele un **agent** peut √™tre l‚Äôhomme tandis que **l‚Äôenvironnement** la nature. Le d√©v√©loppeur programme cet environnement de telle sorte √† ce que l‚Äôagent soit recompens√© pour une bonne action et p√©nalis√© dans le cas contraire. Dans un environnement un agent √† un ensemble d‚Äôaction permise qu‚Äôon nomme **l‚Äôaction space (Espace d‚Äôaction).** Celui ci peut √™tre continu ou discret **.** Lorsqu‚Äôune action est effectu√© par l‚Äôagent, un nouvel √©tat de l‚Äôenvironnement lui est retourn√© **(state)**

![clipboard.png](inkdrop://file:G0FdoSpxv)
<span id="studies"></span>
# III - Etude des probl√®me li√©e √† la propriet√© des donn√©es

Avant de voir quelque techniques de nettoyage de donn√©es √† base de deep learning, nous allons √©ssayer de voir les probl√®me les plus fr√©quent auquelle on peut faire face en phase de pr√©processing des donn√©es.

## A - Type de Donn√©es manquantes

Il existe suivant la r√©partition des valeurs manquantes plusieurs types de donn√©es manquantes. On distingue entre autre

- **MCAR ‚Üí M**issing **C**ompletly **A**t **R**andom:
Ces types de donn√©es signifie que Les valeurs manquantes sont ind√©pendantes des observations. Par exemple si on recueilles des donn√©es chez diverses √©tudiants et que certaines donn√©es sont perdu on peut les consid√©rer comme compl√®tement al√©atoire car cela n‚Äôa rien √† avoir avec l‚Äô√©tudiant en soit. En terme probabliste soit $M_i$ ****l‚Äô√©v√®nement ‚Äò**Donn√©es manquante pour l‚Äôentr√©e** $i$‚Äô et **D** les donn√©es de l‚Äôentr√©e $i$
  
  
$$
P(M_i/D_i) = P(M_i)
$$

  Toutefois il est difficiles de former ce genre d‚Äôaffirmation car des donn√©es totalement al√©atoire sont rare en r√©alit√©
    
- **MAR ‚Üí M**issing  **A**t **R**andom:
Contrairement au noms, une donn√©s qui est **MAR** n‚Äôest pas manquante du au hasard. En effet cette abscence de donn√©es peut √™tre expliqu√© par d‚Äôautre variable observ√© mais pas par la valeur sp√©cifique de la variable manquante. Pour notre exemple du sondage sur les √©tudiants on remarque que les √©tudiants de classes pr√©pa on plus tendances √† ne pas r√©pondres √† une question donn√©es d‚Äôou la valeur manquantes de celle ci. Ainsi notre valeur manquante peut √™tre expliqu√© par la filli√®re de l‚Äô√©tudiant.
- **NMAR** ‚Üí **N**ot **M**issing  **A**t **R**andom:
Pour finir, ce type de donn√©es est relatif √† la valeur de la variable manquante elle-m√™me. Par exemple pour une interview sur le revenu de certains √©tudiants, certains n'ont pas voulu r√©pondre car ils ont un tr√®s faible revenu (valeur logique de la variable)

## B - Contrainte sur les donn√©es

### 1. Contrainte de types de donn√©es

G√©n√©ralement lorsqu‚Äôon travaille avec les donn√©es il est pr√©f√©rable que toute les donn√©es d‚Äôune m√™me colonne soit du m√™me type. Par exemple une colonne qui contient des entiers ne doit pas contenir de chaine de caract√®re au risque d‚Äôimpacter les r√©sultats de calcul. De plus Il est pr√©f√©rable de travailler avec des donn√©es cat√©gorielle aux maximum. En effet cela am√©liore grandement les performances car chaque valeur de la cat√©gorie est connu √† l‚Äôavance

**Solution:**

- Convertir les donn√©es dans un type commun
- Pour les donn√©es textuelle on peut essayer de les regrouper en un type cat√©gorielle

### 2. Contraintes d‚Äôintervalle

Pour les donn√©es num√©riques, il est n√©cessaire de v√©rifier qu'elles sont dans un bon intervalle. Par exemple, une temp√©rature de 100 degr√©s Celsius indique un r√©sultat anormal. De m√™me, pour les valeurs cat√©gorielles, il faut s'assurer que toutes les valeurs se trouvent dans l'ensemble cat√©goriel. Par exemple un groupe sanguin **Z+** n'a aucun sens.

**Solution:**

- Supprimer les lignes contenant les valeurs abberantes
- Remplacer ces lignes par une valeurs donn√©es (Imputation)

### 3.  Contraintes d‚Äôunicit√©

Dans nos donn√©es on doit S‚Äôassurer de l‚Äôunicit√© d‚Äôune partie des attributs. Par exemple si on collecte des informations sur des √©tudiants d‚Äôune classe, on ne doit pas avoir un √©tudiant avec le m√™me num√©ro d‚Äô√©tudiant, le m√™me nom et le m√™me pr√©nom.

**Solution:**

- Conserver une seule donn√©es
- Fusionner les donn√©es

## C - Probl√®mes des donn√©es textuelles et cat√©gorique

Comme mentionn√©e plus haut, Il est pr√©f√©rable d‚Äôutiliser des donn√©es cat√©gorielles √† la place des donn√©es textuelle ou tout autre type de donn√©es si possibles. Toutefois lors de cette conversion on peut rencontrer certains probl√®mes.
<span id="consistence"></span>
### 1. Consistence des valeurs

Lorsque les donn√©es sont sous forme textuelle, on peut avoir pour une m√™me valeur plusieurs forme, ce qui peut conduire √† une inconsistance de donn√©es. Par exemple dans un dataset les mots `**Lundi**` et `lundi` seront consid√©r√© comme diff√©rent ou encore `Bonjour`   vas √™tre diff√©rent de `Bonjour ` 

### 2. Similarit√© de chaine de caract√®re

De m√™me que pour la consistance des chaines de caract√®re, deux donn√©es bien que diff√©rent au premier abord peuvent en r√©alit√© r√©pr√©senter le m√™me √©l√©ment. Par exemple on peut avoir pour l‚Äô√©quipe du maroc les deux enr√©gistrement suivant: `Equipe Marocaine` , `Equipe de football Marocaine`  on l‚Äôair assez diff√©rents mais on peut remarquer qu‚Äôil r√©pr√©sente le m√™me mot. Ainsi les consid√©rer comme deux cat√©gories diff√©rentes peut √™tre pr√©judiciable. 

**Solution**

La r√©solution de ce probl√®me passe par la comparaison de similarit√© entre chaine de caract√®re. Pour ce faire on peut utiliser plusieurs m√©trique comme:

- La distance de Damerau-Levenshtein
- La distance de Levenhstein
- La distance de Hamming
- La distance de Jaro Distance

Il faut noter que tous ces probl√®mes de donn√©es textuelles et cat√©gorique sont √©galement connu sous le nom d'**Entity Matching** .

## D -  Compl√©tude (Valeur Manquante)

L‚Äôun des plus grand probl√®me de nettoyage des donn√©es est la **compl√©tude.** Celui ci intervient lorqu‚Äôon as des donn√©es manquantes dans notre dataset. Cela peut √™tre de diverse origine: capteur d√©faillant, valeur exhorbitante, ou encorre erreur humaine. Toutefois la pluspart des algorithme de machine learning et notamment de deep learning ne travaille pas avec les valeurs manquantes. Il devient donc n√©cessaire de les remplacer par une valeur ad√©quate. Pour ce faire on aura plusieurs approche

### **Approche de Solution**

- **Suppression des enr√©gistrements avec des valeurs manquantes:** La solution la plus simple mais √©galement la moins recommand√© car lorque le nombre d‚Äôenr√©gistrement ayant des valeurs manquantes augmente cela peut entrainer d‚Äô√©norme perte de donn√©es et donc de pr√©cision dans notre mod√®le de machine learning
- **Imputation:** Cette m√©thode n√©c√©ssite un connaissance du domaine pour choisir le meilleur estimateur pour une valeur donn√©es. Bien que plus compliqu√© elle est recommand√© car elle permet de conserver nos donn√©es. On distingue plusieurs m√©thode d‚Äôimputations. On peut citer entre autre:
    - **Imputation univari√©:** Durant cette m√©thode on vas utiliser uniquement la variable m√®re pour pr√©dire les entr√©es manquantes. On peut par exemple prendre pour les valeurs manquantes la moyenne de la variable m√®re(Variable num√©rique) ou le mode (variable cat√©gorique)
        
      $$
      x = \overline{x}
      $$
        
    - **Imputation multivari√©:** Dans ces m√©thode on vas utiliser d‚Äôautre variable pour pr√©dire les variable manquante. On peut par exemple pour une variable $y$ utiliser la regression lin√©aire avec une ou plusieur autre variable puis ainsi estimer la valeur manquante
        
      $$
      y = aX+b
      $$
    - **Hot - Deck:** C'est un ensemble de m√©thode d‚Äôimputations consistant √† remplacer les valeurs manquantes d‚Äôune observation par ceux de populations similaire observ√©. Pour ce genre de m√©thode on peut utiliser un Algorithme de KNN-Neighbor
        
<span id="technique"></span>
# IV - Technique de nettoyage avec le deep learning

## A. Imputation de valeur discrete √† base de perceptron Multicouche Am√©lior√©

Pour effectuer l‚Äôimputation bon nombre de m√©thodes existe comme nous avions pu le voir On peut avoir entre autre l‚Äôimputation par mode, KNN, autoencoder et autre.Toutefois ces m√©thodes offre g√©n√©ralement de tr√®s bon r√©sultats lorsque les valeurs manquantes sont des valeurs continue. Hors il est tout autant important de travailler avec les valeurs manquantes d‚Äôune distribution discr√®te.

### Apercu de la m√©thode

Pour imputer les valeurs manquantes on vas utiliser une technique √† base de perceptron Multi Couche comme d√©crite sur l‚Äôimage suivante. 

![clipboard.png](inkdrop://file:jm0vycGpc)
<div style="page-break-after: always; visibility: hidden"> 
\pagebreak 
</div>

**Etape 1:** Diviser le dataset en deux parties: 

- $D_{com}$: Le Dataset dont les valeurs ne sont pas nulles
- $D_{miss}$: Le Dataset avec des valeurs manquantes

**Etape 2:** Discretiser les valeurs en utilisant un algorithme de discr√©tisation (comme le one-hot-encoding) puis les faires entrer dans le `IMLP` (MLP am√©lior√© avec algorithm de descente de gradient avec momentum) qui vas remplir les valeurs manquantes

**Etape 3:**  Recombiner $D_{com}$ et $D_{miss}$ pour retrouver le dataset original. On note que $D_{miss}$ seras √† cette √©tape remplis avec des valeur estim√© par l'algorithme

**Etape 4:** Evaluer les performances du mod√®le



### Explication d√©taill√© de la m√©thode
**1. D√©termination des types avec valeur manquantes**

Soit $D$ notre dataset. On a $D_{miss}$ qui correspond au datasets avec les entr√©es manquantes et $D_{com}$ le datasets avec les donn√©es compl√®tes. Dans le datasets manquants, on aura $A_i(i =1..n)$ ou $n$ est le nombre de feature du dataset. Dans la grille suivante on peut voir une mod√©lisation du Dataset ou les cases noires correspondent au donn√©es manquantes.

![clipboard.png](inkdrop://file:7CfcveILz)

Pour chaque ligne $i$ on vas noter les types manquants $mt_i$. Par exemple suivant notre sh√©mas, $mt_1 = {1, 2, n}$. On obtient ainsi l'ensemble des types manquants $MT = {mt_i \space i \in (1..m) }$ ou $m$ r√©pr√©sente le nombre d'enr√©gistrement de $D_{miss}$

**2. Constructions du IMLP**

Pour notre r√©seaux de neurone la couche d'entr√©e vas prendre l'espace des enr√©gistrement $X = {x_1, x_2, ..., x_m}$ ou $x_i$ correspond √† un enr√©gistrement du Dataset. De m√™me la couche de sorties vas contenir $n$ neurone qui vont chacun correspondre √† une **feature** des donn√©es. Les couches cach√© vont utiliser une fonction d'activation $relu(x)$ tandis que la couche de sortie vas utilser une foncton $sigmoid(x)$. Le IMLP ne pouvant pas traiter directement avec les valeurs manquantes on vas les pr√©-remplir avec une valeur donn√©es.

**3. Entrainement du mod√®le**

Avant l'entrainement du mod√®le on doit s'assurer que les valeurs discr√®tes du mod√®les (Valeurs textuelle, Entier) soit discr√©tiser. On peut par exemple utiliser la technique du **one-hot**. Cela vas permettre d'obtenir des valeurs discr√®tes pour la pr√©dictions. Ensuite on vas se servir de $D_{com}$. De plus on vas diviser $D_{com}$ en train-set et test-set pour effectuer l'entrainement. Pour $D_{miss}$ on vas faire entrer dans le mod√®le les valeurs pr√©sente plus les valeurs absentes seront d√©duites

**4. Reconstruction du datasets incomplet**

Durant cette phase le but seras d'utiliser le IMLP entrain√© pour pr√©dire les valeurs manquantes de $D_{miss}$.La premi√®re √©tapes seras de d√©terminer les types manquants du datasets ($mt_i$). Les donn√©es manquantes seront remplis une par une pour enfin g√©n√©rer un dataset complet.
![clipboard.png](inkdrop://file:_SZSg4yn1)

## B. Transformation automatique des donn√©es √† bases de Deep Reinforcement Learning

Avant d'entra√Æner un mod√®le il est souvent n√©cessaire d'effectuer un certain nombre de transformations. Par exemple pour une image, il peut √™tre n√©cessaire de filtrer, renverser ou couper ces images avant de pouvoir les faires passer aux r√©seaux de de Neurone. Toutefois ces transformations bien que r√©p√©titives sont toujours faites par intervention. Dans la perspective de notre √©tude nous allons voir une technique √† base de Reinforcement learning √† base de Deep Learning qui va permettre d'appliquer directement des transformations donn√©es √† un ensemble de donn√©es.

### Motivation
Bon nombre de scientists se sont pench√© sur l'automatisation de la transformation des donn√©es.Toutefois la plupart de ces √©tudes sont m√©n√© sur un nombre relativement limit√© de transformation comme la **normalisation**, **standarisation** ou **dicretisation.**. De plus ces √©tudes applique les transformations sur tout l'ensemble de donn√©es plutot que d'appliquer une transformation sp√©cifique. En effet la transformation des donn√©es r√©pr√©sente bon nombre de challenge. Pour une donn√©e $D$ et deux transformation $T$ et $P$ , il est important de remarquer que $T(D) + P(D) \neq P(D) + T(D)$ car l'ordre des transformation est important. De plus avec un nombre important de transformation le temps d'apprentisage seras √©normes. De plus comme vu pr√©c√©demment appliquer le m√™me ensemble de transformation √† tous un Datasets peut √™tre inn√©ficaces car chaque donn√©es √† sa sp√©cifit√©. Par exemple deux images ayant √©t√© pris d'un diff√©rents angle et qui recoivent une rotation de 90 d√©gr√© n'auront aucun sens. Enfin une mauvaise transformation peut totalement affecter le sens de la donn√©e. Par exemple une rotation de 180 d√©gr√© sur le chiffre **9** vas donner le chiffre **6**.

### Apercu du framework
Comme tout algorithme de Reinforcement learning on aura un **agent** et un **environnement**. Dans notre cas l'agent seras un r√©seaux de neuronne dont la sorties seras un ensemble de transformation qui seront utilis√© par un chef d'orchestre qui vas d√©cider si l'image n√©cessite plus de transformation ou peut √™tre consid√©r√© comme correctement transform√©. Lorsque le chef d'orchestre d√©cide que l'image n√©cessite d'√™tre transform√©, l'environnement vas se charger de cette transformations puis vas renvoyer l'image dans le r√©seaux de neuronne pour une nouvelle √©valuation. Ce processus seras r√©p√©t√© jusqu'a ce que le chef d'orchestre juge que l'image est correctement transform√©. De plus pour que l'agent apprenne , l'environnement vas √©valuer l'impact des transformations effectu√© puis envoyer une r√©compenses bas√©s sur celle ci. Ce processus est resum√© dans l'image suivante.
![clipboard.png](inkdrop://file:DsSed4mRt)
#### 1. Espaces d'action et Etats
##### 1.1 Espaces des Etats
Les √©tats dans notre frameworks seront les images. L'√©tat original vas correspondre √† l'image d'origine. Apr√®s chaque transformations un nouvel √©tats seras retourn√© par l'environnement
##### 1.2 Espaces des actions
Pour notre √©tude un **Deep Q-Network (DQN)** seras utilis√©. La couche de sorties vas √™tre l'espaces des actions et seras constitu√© de deux types. La premi√®re parties est un vecteur logique qui vas contenir la probablit√© d'appartenance √† la classe $k$, elle est n√¥t√© $S_{actions} = (S_{actions_1}, S_{actions_2}, ... S_{actions_k})$. Ce type d'action vont √™tre des actions d'arr√™ts en effet si le chef d'orchestre choisi une action $S_{actions_i}$ alors le processus vas s'arr√™ter et vas pr√©dire la classes $i$ pour l'image. La seconde actions quand √† elle, vas contenir une ensemble de $n$ transformations $T_{actions} = (T_{actions_1}, T_{actions_2}, ... T_{actions_n})$. Si une transformation $i$ doit √™tre effectu√© le chef d'orchestre vas choisir une action $T_{actions_i}$. Ces deux ensembles d'actions forme ainsi un Espaces d'actions de tailles $k+n$. On remarque que la premi√®re partie de cet ensemble est adapt√© √† la tache du r√©seau (dans notre cas une classification).

![clipboard.png](inkdrop://file:hfy_TmN8d)
##### 1.3 Restaurations des transformations
Pour chaque transformations $A$ appliqu√© il est important d'avoir une transformation $-A$ qui peut lui √™tre appliqu√© pour annuler l'effet de la transformation $A$. En effet si cette tranformations conduit √† un r√©sultat sous performant il peut √™tre interressant de l'annuler. Pour des transformations complexe cela peut conduire √† une grande consommation de m√©moire. Toutefois on vas utiliser un m√©chanisme pour controller le nombre maximum de transformations pouvant √™tre appliqu√©.

#### 2. Chef d'orchestre
C'est l'une des pieces les importantes du framework. C'est lui qui vas se charger de choisir une action donn√©e puis le passer √† l'environnement si n√©cessaire. Dans notre cas on vas utiliser une politique de choix maximum qui vas consiter √† prendre le maximum des actions de l'espace d'action.De plus le chef d'orchestre auras la possibilit√© de choisir l'action suivante avec une probablit√© $\epsilon$ qui vas commencer √† $\epsilon=1$

#### 3. Le r√©seaux de Neurone
La variante de **DQN** utilis√© dans notre √©tude est un **DQN** nomm√©es [Dueling DQN (DDQN)](https://towardsdatascience.com/dueling-deep-q-networks-81ffab672751). Pour mettre √† jour le r√©seaux de neurone, **l'√©quations de bellman** seras utilis√©. Elle se d√©finit comme suit

$$
Q(s, a) = r + \gamma * max_{a'}(Q(s', a'))
$$
- $Q(s, a)$: C'est la sortie du neurone pour une action $a$ dans un √©tat $s$
- $r$:  Est la recompenses retourn√© par l'environnement
- $s'$: Correspondante √† l'√©tat retourn√© par l'environnement lorque l'action $a$ est appliqu√© √† l'√©tat $s$
- $\gamma$: c'est le param√®tre de discount

#### 4. L'environnement
L'environnement est le lieu ou sont appliqu√© les transformations. Il seras √©galement responsable du calcul des recompenses. Il recoit donc une image et une action du chef d'orchestre puis l'applique. Si l'environnement recoit une action de transformations $T_{actions_i}$, il v√©rifie si cette chaine d'action a une longueur inf√©rieur √† un param√®tre $m$ qu'on aura configur√© (Pour √©viter une saturation de m√©moire pour les chaines de transformations tr√®s longues). L'action seras uniquement effectu√© si la longueur est v√©rifi√© sinon une autre action seras recherch√©. Dans le cas ou la longueur est sup√©rieur √† $m$ une r√©compense de z√©ro est renvoy√© puis l'image est restaur√©. Toutefois √† la phase de test, l'action d'arr√™t avec la plus grande valeur de $Q$ seras retourn√©. Dans le cas ou l'environnement recoit une action d'arr√™t $S_{actions_j}$, il ne retourne pas d'image au r√©seaux mais juste une r√©compenses puis classifie l'image comme une image de classe $j$. Le syst√®mes de r√©compenses est tr√®s important dans la convergence de l'algorithme. Une solution simple peut √™tre de retourner $+1$ si apr√®s la transformations la classes pr√©dictes de l'image est correcte et $-1$ sinon. Toutefois avec plusieurs classes de tailles $k$ cette solution n'est pas tr√®s efficace. Ainsi pour une pr√©dictions correcte apr√®s transformations, l'environnement retourne  $k - 1$ et $-1$ sinon.
![clipboard.png](inkdrop://file:vCjGj5SD7)
# D. R√©seaux de Neurone pour entity Matching
L**'entity matching** peut √™tre consid√©r√© comme un secteur de recherche visant √† identitifier si deux enr√©gistrement **A** et  **B** r√©f√®rent √† la m√™me entit√© r√©el. Malgr√© des d√©cennies de recherches et l'av√®nment des nouvelle technologie de machine learning, l'entity mactching reste un probl√®me pour les raisons suivantes:
- **Faible qualit√© de donn√©es**: Les donn√©es peuvent contenir des erreurs ou des manques de pr√©cisions (par exemple `{firstName: "Machkour Oke", lastName: "Etudiant"})`). De plus elle peuvent √™tre [inconsistente](#consistence), ou suivre un sh√©ma diff√©rent en fonction du lieu d'enr√©gistrement

- **Le grand nombre de match possible (Element similaire)**: Soit un $A$ un dataset de taille $n$ et $B$ de taille $n$ √©galement on peut avoir $n*n$ match soit une complexit√© de $O(n^2)$. On peut g√©n√©ralement esp√©rer avoir $n$ match. Toutefois comparer toutes les paires est tr√®s couteux en calcul.
- **D√©pendance envers les connaissances humaines et connaissances domaines**: Bien qu'il soit possible d'automatiser un cetains nombre de probl√®me d'entity Matching, un bon nombre de probl√®me ne dispose pas en eux m√™mes des informations n√©cessaires et doivent ainsi faire appel √† un expert pour conclure

## D√©finition du probl√®me
  Soit $A$ et $B$ deux sources de donn√©es de features(caract√©ristiques) respectifs $(ùê¥_1, ùê¥_2, . . ., ùê¥_ùëõ )$ , $(B_1, B_2, . . ., B_√π )$. Nous d√©noterons $ùëé = (a_1, a_2, ..., a_n) ‚àà ùê¥$ et $b = (b_1, b_2, ..., b_m) ‚àà B$ les enr√©gistrement respectifs de $A$ et $B$. Le but de **l'entity Matching** seras de trouver le plus grand ensemble $M \subseteq A * B$ telle que pour tout $a$ et $b$ appartenant √† $M$ $(a, b)$ ref√®re √† la m√™me entit√© r√©elle. Le probl√®me de duplication des donn√©es est un sous probl√®me de l'entity Matching ou $A = B$
  
  ![clipboard.png](inkdrop://file:o1Umlrltv)

## Exemple de probl√®me d'entity Matching
L'entity matching peut √™tre rencontr√© dans bon bon nombre de contexte allant de la simple duplication de donn√©es √† la jointure de donn√©es. Quelques probl√®mes populaires de l'entity matching sont:
- **R√©solution des cor√©f√©rences :** En NLP (Natural language processing), cette tache consiste √† trouver dans un texte tous les mots qui ref√®re √† la m√™me entit√©. Cela peut √™tre utile pour effectuer des r√©sum√© de texte, des r√©ponses √† des questions ou autres
- **Alignement d'entit√©:** Cette tache est correspond √† trouver dans deux bases de donn√©es les donn√©es qui ref√®rent √† la m√™me entit√©. Cela peut √™tre utile pour d√©tecter un m√™me utilisateurs √† travers deux bases de donn√©es par exemple
- **Liaison d'entit√©:** Pour un texte donn√©es trouver toutes les mentions d'une entit√© puis les lier dans une bases de donn√©es. Cette op√©rations peut √™tre vu comme un m√©lange entre **l'alignement d'entit√©** et **la r√©solution de cor√©f√©rences**
- **Identification de paraphrase:** Pour deux texte donn√©es d√©terminer s'ils ont le m√™me sens. Cela peut √™tre utilis√© pour d√©tecter des plagiats par exemple. Toutefois l'entity matching n'est qu'une partie de ce probl√®me

## Processus de l'entity matching
### Pr√©processing des donn√©es
Bien que l'entity matching peut √™tre dans l'une des phases de pr√©processing, il est important d'effectuer toutes les autres transformations √©l√©mentaires aux donn√©es. Par exemple s'assurer de la [consistance des donn√©es](#consistence), ou parfois extraire les features importante du mod√®le par exemple

### Correspondance de sh√©ma
Dans cette partie on vas chercher les attributs comparable dans les deux sources de donn√©es. Lorsqu'on as une m√™me table ou une structure identique dans les deux tables, la correspondance est trivial. G√©n√©ralement cette √©tape seras effectu√© √† la main car pour son automatisation peut rentrer encore dans un autre types de probl√®mes

### Blocage
L'ensemble des match potentiels $A * B$ croit de mani√®re quadratique avec la taille des donn√©es. Pour √©viter d'avoir √† comparer toutes les paires possibles, on prend un ensemble $C \subseteq A * B$ de paires candidates. Cela est d√©fini comme une comparaison explicite et moin couteuse qu'une comparaison implicite (qui seras fait par la suite). Elle vas supprimer dans les paires de matches les paires dont le non-matching est √©vident.Il existe plusieurs techniques pour le faire. On peut par exemple choisir une des colonnes $A_i$ et sa colonne correspondant $B_i$ puis sp√©cifier un seuil de similarit√© √† partir duquel on conserve les pairs.

### Comparaison de pair d'enr√©gistrement
Dans cette √©tapes on vas faire une comparaison explicite des des paires $(a, b) \in C$. Cette comparaison vas donner un vecteur de similarit√© $S$ indiquant la similarit√© au noveau de chaque attribut entre les deux sources de donn√©es

### Classification
L'objectif de cette phase est de d√©clarer ou non les paires correpondantes. Dans le cas ou $|S| = 1$ on peut fixer un seuil au bout duquel les pairs sont correpondantes ou non. Dans le cas ou $|S| > 1$, des m√©thodes plus sophistiqu s'impose. Il faut noter qu'on peut obtenir trois type de r√©sultats: **match**, **nonmatch** et incertains. Les paires incertaines auront besoin d'une v√©rification manuelle

## Application avec des r√©seaux de neurone
### Data preprocessing
Les r√©seaux de neurone comme la plupart des algorithme de machine learning ne fonctionne qu'avec des donn√©es num√©riques. Pour les donn√©es textuelle il est donc n√©cessaire de les convertir en donn√©es num√©rique. Ce processus est appel√© l'embedding. Il existe plusieurs algorithme d'embedding comme le **word2vec** qui est un r√©seaux de neurone que nous n'allions pas d√©tailler ici.

### Correspondance de sh√©ma
Pour deux sources de donn√©es $A$ et $B$, les sh√©mas de ces deux sources de donn√©e peuvent √™tre dans trois cas:
- **Shemas align√©:** Les deux sources de donn√©es utilisent le m√™me sh√©ma: 
